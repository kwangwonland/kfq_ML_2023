{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMK5jfJoTMyM7I5KtbHL3XX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwangwonland/kfq_ML_2023/blob/main/0726_%ED%85%8D%EC%8A%A4%ED%8A%B8_%EC%83%9D%EC%84%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ro5rOs6Mhmqc",
        "outputId": "10df1f66-2f1c-4f6b-9365-4646df59bd9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-26 00:09:17--  https://ai.stanford.edu/~amaas/data/sentiment/acllmdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2023-07-26 00:09:18 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/acllmdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH55dy2PhyDA",
        "outputId": "8802ebe6-c775-4bb8-dbd2-94e374e655e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-26 00:12:02--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  21.4MB/s    in 5.9s    \n",
            "\n",
            "2023-07-26 00:12:08 (13.5 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "id": "74IwxtOyic5j"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "2Xcz-mGbixSz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=keras.utils.text_dataset_from_directory(\n",
        "    directory='aclImdb',\n",
        "    label_mode=None,\n",
        "    batch_size=256\n",
        ")\n",
        "dataset=dataset.map(lambda x:tf.strings.regex_replace(x,'<br /',' '))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjD8voxAjP9N",
        "outputId": "28df6e22-4de0-4711-ff48-6194fafcf9d6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100006 files belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in dataset:\n",
        "    print(len(batch))\n",
        "    for text in batch:\n",
        "        print(text)\n",
        "        break\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0KjlzMWjjtU",
        "outputId": "a0d8beba-0b5b-4bdf-d639-150305a86ec9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "256\n",
            "tf.Tensor(b\"This film NAILS it by juxtaposing the fast rise and rocky descent of 80's counter-culture commercialism with the tragic story of Gator and his victim. We get to know Gator as a wild punk, arrogant jock, immature romantic, and finally, a violent and dangerous man. He was made for stardom, but the path to skater stardom was even younger than its pioneers... he was the era's most notable fallen angel.  > >I haven't yet seen a more vivid reflection on the style and attitude of California in the 1980s. It's very easy to get lost in this one; it's a sad, enlightening, and socially significant piece of journalistic film-making. Kudos to the filmmakers.\", shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers"
      ],
      "metadata": {
        "id": "oBu02BMUk9fP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length=100\n",
        "vocab_size=15000\n",
        "tv=layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length\n",
        ")\n",
        "tv.adapt(dataset)"
      ],
      "metadata": {
        "id": "p4FKE7zujxNN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in dataset:\n",
        "    print(len(batch))\n",
        "    for text in batch:\n",
        "        print(text)\n",
        "        vs=tv(text)\n",
        "        print(vs)\n",
        "        break\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9YNEmFglHpP",
        "outputId": "052a0476-efa3-4f67-fd9d-fd2bc81f4245"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "256\n",
            "tf.Tensor(b'This movie was terrible. It is not something that people should have to pay to see. It looks like some Christian group made it to convert people. I don\\'t understand why it was released to theaters and not to TV. > >It started out like an old fashioned B movie sci-fi film from the 50s, but quickly changed. About 30 minutes into the movie the characters start talking about \"God\" and \"Do you believe in Jesus?\" It quickly moves into pure religion territory. > >I thought I was going to a Sci-Fi movie. The film has poor acting; bad camera angles and is amateurish. > >AVOID IT!', shape=(), dtype=string)\n",
            "tf.Tensor(\n",
            "[   11    17    13   379     9     7    22   137    12    83   140    25\n",
            "     6   975     6    65     9   279    38    46  1630   516    96     9\n",
            "     6 11901    83    10    89   375   132     9    13   632     6  2090\n",
            "     3    22     6   245     9   655    45    38    33   171  4875   962\n",
            "    17   866    19    35     2  2135    18   912  1153    42  1193   227\n",
            "    77     2    17     2   100   358   685    42   605     3    80    21\n",
            "   256     8  2475     9   912  1100    77  1038  2416  3184    10   195\n",
            "    10    13   161     6     4   866    17     2    19    43   326   115\n",
            "    76   378  2472     3], shape=(100,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in dataset:\n",
        "  vs = tv(batch)\n",
        "  x = vs[:,:-1]\n",
        "  y = vs[:,1:]\n",
        "  break\n",
        "print(vs[0])\n",
        "print(x[0])\n",
        "print(y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SU0cqIql78L",
        "outputId": "6408db75-180c-44b4-aa6d-f01dc41d6d35"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[    9   181     2  1078     5    11    19   195    34   910     6  6551\n",
            "     2  3657     8   618     6    95     4    64    12     7     1     3\n",
            " 14974  3710  9488    40     4  2323    34   398    25  2361     4    64\n",
            "    12    13   156   293     3     8     2  3657  1718  3140  5467     5\n",
            "     1    20  5693     3 11859    16  3145   878  8216   317   325    37\n",
            "    13  2475   317   488    39   137     8   196    36   675     3    36\n",
            "  2028     2  3657   110   696   170     3    54   409  1264  5350  1636\n",
            "    85  3943    54  3568    66   121   225     5  2475   350    42  9601\n",
            "   151   101    24   315], shape=(100,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[    9   181     2  1078     5    11    19   195    34   910     6  6551\n",
            "     2  3657     8   618     6    95     4    64    12     7     1     3\n",
            " 14974  3710  9488    40     4  2323    34   398    25  2361     4    64\n",
            "    12    13   156   293     3     8     2  3657  1718  3140  5467     5\n",
            "     1    20  5693     3 11859    16  3145   878  8216   317   325    37\n",
            "    13  2475   317   488    39   137     8   196    36   675     3    36\n",
            "  2028     2  3657   110   696   170     3    54   409  1264  5350  1636\n",
            "    85  3943    54  3568    66   121   225     5  2475   350    42  9601\n",
            "   151   101    24], shape=(99,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[  181     2  1078     5    11    19   195    34   910     6  6551     2\n",
            "  3657     8   618     6    95     4    64    12     7     1     3 14974\n",
            "  3710  9488    40     4  2323    34   398    25  2361     4    64    12\n",
            "    13   156   293     3     8     2  3657  1718  3140  5467     5     1\n",
            "    20  5693     3 11859    16  3145   878  8216   317   325    37    13\n",
            "  2475   317   488    39   137     8   196    36   675     3    36  2028\n",
            "     2  3657   110   696   170     3    54   409  1264  5350  1636    85\n",
            "  3943    54  3568    66   121   225     5  2475   350    42  9601   151\n",
            "   101    24   315], shape=(99,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_Im_dataset(text_batch):\n",
        "    vs=tv(text_batch)\n",
        "    x=vs[:,:-1]\n",
        "    y=vs[:1,1:]\n",
        "    return x,y"
      ],
      "metadata": {
        "id": "9ydxkC9_m9VL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Im_dataset=dataset.map(prepare_Im_dataset,num_parallel_calls=4)"
      ],
      "metadata": {
        "id": "LTHaUMKMn840"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 2"
      ],
      "metadata": {
        "id": "IDgZQTJRoE_1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "wfNgvbVTqJCe"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "  def __init__(self,sequence_length,input_dim,output_dim,**kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.token_embeddings = layers.Embedding(input_dim,output_dim)\n",
        "    self.position_embeddings = layers.Embedding(sequence_length,output_dim)\n",
        "    self.sequence_length = sequence_length\n",
        "    self.input_dim = input_dim\n",
        "    self.output_dim = output_dim\n",
        "  def call(self,inputs):\n",
        "    length = tf.shape(inputs)[-1]\n",
        "    positions = tf.range(start=0,limit=length,delta=1)\n",
        "    embedded_tokens = self.token_embeddings(inputs)\n",
        "    embedded_positions = self.position_embeddings(positions)\n",
        "    return embedded_tokens + embedded_positions\n",
        "  def compute_mask(self,inputs,mask=None):\n",
        "    return tf.math.not_equal(inputs,0)\n",
        "  def get_config(self):\n",
        "    config = super(PositionalEmbedding,self).get_config()\n",
        "    config.update(\n",
        "        {\n",
        "            \"output_dim\":self.output_dim,\n",
        "            \"sequence_length\":self.sequence_length,\n",
        "            \"input_dim\":self.input_dim,\n",
        "        }\n",
        "    )\n",
        "    return config"
      ],
      "metadata": {
        "id": "ZLjq43-_q1-W"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "          num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "          num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(TransformerDecoder, self).get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1),\n",
        "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(\n",
        "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask)\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        attention_output_2 = self.layernorm_2(\n",
        "            attention_output_1 + attention_output_2)\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2 + proj_output)"
      ],
      "metadata": {
        "id": "D1oIcezNysYp"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(None,),dtype='int64')\n",
        "x = PositionalEmbedding(sequence_length,vocab_size,embed_dim)(inputs)\n",
        "x = TransformerDecoder(embed_dim,latent_dim,num_heads)(x,x)\n",
        "outputs = layers.Dense(vocab_size,activation='softmax')(x)\n",
        "model = keras.Model(inputs,outputs)\n",
        "model.compile(loss = keras.losses.sparse_categorical_crossentropy)"
      ],
      "metadata": {
        "id": "ofyo1ZU6oOyD"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "tokens_index=dict(enumerate(tv.get_vocabulary()))"
      ],
      "metadata": {
        "id": "j2cTvhbtoYV1"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_next(predictions, temperature=1.0):\n",
        "    predictions = np.asarray(predictions).astype(\"float64\")\n",
        "    predictions = np.log(predictions) / temperature\n",
        "    exp_preds = np.exp(predictions)\n",
        "    predictions = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, predictions, 1)\n",
        "    return np.argmax(probas)"
      ],
      "metadata": {
        "id": "tWsrYT6H-AsK"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextGenerator(keras.callbacks.Callback):\n",
        "    def __init__(self,\n",
        "                 prompt,\n",
        "                 generate_length,\n",
        "                 model_input_length,\n",
        "                 temperatures=(1.,),\n",
        "                 print_freq=1):\n",
        "        self.prompt = prompt\n",
        "        self.generate_length = generate_length\n",
        "        self.model_input_length = model_input_length\n",
        "        self.temperatures = temperatures\n",
        "        self.print_freq = print_freq\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % self.print_freq != 0:\n",
        "            return\n",
        "        for temperature in self.temperatures:\n",
        "            print(\"== Generating with temperature\", temperature)\n",
        "            sentence = self.prompt\n",
        "            for i in range(self.generate_length):\n",
        "                tokenized_sentence = tv([sentence])\n",
        "                predictions = self.model(tokenized_sentence)\n",
        "                next_token = sample_next(predictions[0, i, :])\n",
        "                sampled_token = tokens_index[next_token]\n",
        "                sentence += \" \" + sampled_token\n",
        "            print(sentence)"
      ],
      "metadata": {
        "id": "Ze0CXSP5-7_R"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"This movie\"\n",
        "text_gen_callback = TextGenerator(\n",
        "    prompt,\n",
        "    generate_length=50,\n",
        "    model_input_length=sequence_length,\n",
        "    temperatures=(0.2, 0.5, 0.7, 1., 1.5))"
      ],
      "metadata": {
        "id": "Ptn-JoKD_CCh"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(Im_dataset,epochs=3,callbacks=[text_gen_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Tkte4My1AAwp",
        "outputId": "db4b86cb-0455-40f9-dac9-f46780ae6519"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-9864fc24e325>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIm_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext_gen_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-48-9864fc24e325>\", line 1, in <cell line: 1>\n      model.fit(Im_dataset,epochs=3,callbacks=[text_gen_callback])\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 2078, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/backend.py\", line 5660, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert'\nassertion failed: [Condition x == y did not hold element-wise:] [x (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [1 99] [y (sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [256 99]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert}}]] [Op:__inference_train_function_4944]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eD37ch-xA2MQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}